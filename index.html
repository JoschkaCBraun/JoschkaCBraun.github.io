
    <!doctype html>
    <html lang="en">
    <head>
        <!-- Existing meta tags and Bootstrap CSS link -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" crossorigin="anonymous">
        <link rel="stylesheet" <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha512-DTOQO9RWCH3ppGqcWaEA1BIZOC6xxalwEsw9c2QQeAIftl+Vegovlnee1c9QX4TctnWMn13TZye+giMm8e2LwA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
        </style>
        <title>Joschka Braun</title>
        <link rel="icon" type="image/x-icon" href="assets/icon.ico">
    </head>

    <body>
        <div class="container">
            <div class="row" style="margin-top: 3em;">
                <div class="col-sm-12" style="margin-bottom: 1em; text-align: center;">
                    <h3 class="display-4"><span style="font-weight: bold;">Joschka</span> Braun</h3>
                    
    <div class='container'>
        <div class='row justify-content-center'>
            <div class='col-auto mb-2'><a href='https://joschkacbraun.github.io/assets/pdf/CV_Joschka_Braun.pdf' target='_blank'><i class='fa fa-address-card fa-lg'></i> CV</a></div>
            <div class='col-auto mb-2'><a href='mailto:joschkacbraun@gmail.com'><i class='far fa-envelope-open fa-lg'></i> Mail</a></div>
            <div class='col-auto mb-2'><a href='https://github.com/JoschkaCBraun' target='_blank'><i class='fab fa-github fa-lg'></i> Github</a></div>
            <div class='col-auto mb-2'><a href='https://huggingface.co/Joschka' target='_blank'><img src='assets/huggingface-logo.svg' alt='Hugging Face' style='width: 27px; height: 27px; vertical-align: middle; margin-right: 4px;'> Hugging Face</a></div>
            <div class='col-auto mb-2'><a href='https://scholar.google.com/citations?&hl=en&user=hsNmAWYAAAAJ&hl=en' target='_blank'><i class='fa-solid fa-book'></i> Scholar</a></div>
            <div class='col-auto mb-2'><a href='https://orcid.org/0009-0001-0281-2091' target='_blank'><i class='fa-brands fa-orcid'></i> ORCID</a></div>
            <div class='col-auto mb-2'><a href='https://x.com/BraunJoschka' target='_blank'><i class='fab fa-x-twitter fa-lg'></i> X</a></div>
            <div class='col-auto mb-2'><a href='https://bsky.app/profile/joschkabraun.bsky.social' target='_blank'><img src='assets/bluesky-logo.svg' alt='Bluesky' style='width: 16px; height: 16px; vertical-align: middle; margin-right: 4px; display: inline-block;' onerror="this.style.display='none'; this.nextSibling.style.display='inline';"><i class='fas fa-cloud' style='display: none; color: #0085FF;'></i> Bluesky</a></div>
            <div class='col-auto mb-2'><a href='https://www.linkedin.com/in/joschka-braun' target='_blank'><i class='fab fa-linkedin fa-lg'></i> LinkedIn</a></div>
        </div>
    </div>
    
                </div>
                <div class="col-md-7">
                    
                <p>
                    I am a machine learning researcher focused on developing trustworthy, interpretable, and socially beneficial AI systems.
                </p>
                <p>
                    Currently, I'm a scholar in the <a href="https://www.matsprogram.org/" target="_blank">ML Alignment & Theory Scholars (MATS) Program</a>, working on Scalable Oversight and AI Control with 
                    <a href="https://scholar.google.com/citations?user=p_aH5fgAAAAJ&hl=en" target="_blank">David Lindner</a>, 
                    <a href="https://rzimmermann.com/" target="_blank">Roland Zimmermann</a>, and 
                    <a href="https://scholar.google.com/citations?user=LoT0z6oAAAAJ&hl=en" target="_blank">Scott Emmons</a>.
                </p>
                <p>
                    My previous research includes work on the reliability of steering vectors in Large Language Models with <a href="https://krasheninnikov.github.io/about/" target="_blank">Dmitrii Krasheninnikov</a> and <a href="https://scholar.google.ca/citations?user=5Uz70IoAAAAJ&hl=en" target="_blank">David Krueger</a> at the <a href="https://www.kasl.ai/" target="_blank">Krueger AI Safety Lab</a> at the University of Cambridge. I have also worked on applications of representation engineering at the <a href="https://health-nlp.com/" target="_blank">Health-NLP</a> group, supervised by 
                    <a href="https://scholar.google.ch/citations?user=UkzwC_EAAAAJ&hl=en" target="_blank">Seyed Ali Bahrainian</a> and 
                    <a href="https://scholar.google.com/citations?user=QQi1_rAAAAAJ&hl=en" target="_blank">Carsten Eickhoff</a>.
                </p>
                <p>
                    I am passionate about public debate and democratic discourse to shape informed perspectives and drive effective policy.
                </p>
                <p>
                    I hold a Master’s degree in Machine Learning and a Bachelor’s degree in Computer Science from the <a href="https://uni-tuebingen.de/" target="_blank">University of Tübingen</a>. My research sits at the intersection of Deep Learning and Natural Language Processing, motivated by the challenge of building safe and equitable AI systems. As AI technologies improve, I aim to help address societal risks and promote equitable benefits by advancing scientific understanding and supporting effective governance.
                </p>
                <p>
                    Feel free to reach out to me via mail!
                </p>
                
                </div>
                <div class="col-md-4 text-center" style="">
                    <img src="assets/img/profile.png" style="width: 100%; max-width: 280px; height: auto; border-radius: 50%;" alt="Profile picture">
                </div>
            </div>
            <div class="row" style="margin-top: 1em;">
                <div class="col-sm-12" style="">
                    <h4>Publications</h4>
                    <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/icml_2025_r2fm_workshop.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://openreview.net/forum?id=sbm53EmmGp" target="_blank">Beyond Multiple Choice: Evaluating Steering Vectors for Adaptive Free-Form Summarization</a> <br><span style="font-weight: bold";>Joschka Braun</span>, <a href="https://scholar.google.com/citations?user=QQi1_rAAAAAJ&hl=en" target="_blank">Carsten Eickhoff</a>, <a href="https://scholar.google.ch/citations?user=UkzwC_EAAAAJ&hl=en" target="_blank">Seyed Ali Bahrainian</a> <br><span style="font-style: italic;">ICML 2025 Workshop on Reliable and Responsible Foundation Models</span>, 2025 <br><a href="https://openreview.net/forum?id=sbm53EmmGp" target="_blank">Paper</a> / <a href="assets/pdf/icml_2025_r2fm_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/JoschkaCBraun/adaptive-text-steering" target="_blank">Code</a> / <a href="https://arxiv.org/abs/2505.24859" target="_blank">arXiv</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsebraun2025beyond" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapsebraun2025beyond"><div class="card card-body"><pre><code>@InProceedings{braun2025beyond, 
	author = {Joschka Braun and Carsten Eickhoff and Seyed Ali Bahrainian}, 
	title = {Beyond Multiple Choice: Evaluating Steering Vectors for Adaptive Free-Form Summarization}, 
	booktitle = {ICML 2025 Workshop on Reliable and Responsible Foundation Models}, 
	year = {2025}, 
	eprint = {2505.24859}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/iclr_2025_fmwild_workshop.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="assets/pdf/iclr_2025_fmwild_workshop.pdf" target="_blank">Understanding (Un)Reliability of Steering Vectors in Language Models</a> <br><span style="font-weight: bold";>Joschka Braun</span>, <a href="https://scholar.google.com/citations?user=QQi1_rAAAAAJ&hl=en" target="_blank">Carsten Eickhoff</a>, <a href="https://scholar.google.ca/citations?user=5Uz70IoAAAAJ&hl=en" target="_blank">David Krueger</a>, <a href="https://scholar.google.ch/citations?user=UkzwC_EAAAAJ&hl=en" target="_blank">Seyed Ali Bahrainian</a>, <a href="https://krasheninnikov.github.io/about/" target="_blank">Dmitrii Krasheninnikov</a> <br><span style="font-style: italic;">ICLR 2025 Workshop on Foundation Models in the Wild</span>, 2025 <br><a href="assets/pdf/iclr_2025_fmwild_workshop.pdf" target="_blank">Paper</a> / <a href="https://arxiv.org/abs/2505.22637" target="_blank">arXiv</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsebraun2025understanding" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapsebraun2025understanding"><div class="card card-body"><pre><code>@InProceedings{braun2025understanding, 
	author = {Joschka Braun and Carsten Eickhoff and David Krueger and Seyed Ali Bahrainian and Dmitrii Krasheninnikov}, 
	title = {Understanding (Un)Reliability of Steering Vectors in Language Models}, 
	booktitle = {ICLR 2025 Workshop on Foundation Models in the Wild}, 
	year = {2025}, 
	eprint = {2505.22637}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/bsc_thesis.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="assets/pdf/bsc_thesis.pdf" target="_blank">Verbal Epistemic Uncertainty Estimation for Numeric Values with GPT-3</a> <br><span style="font-weight: bold";>Joschka Braun</span> <br><span style="font-style: italic;">BSc Thesis at Univesity of Tübingen</span>, 2022 <br><a href="assets/pdf/bsc_thesis.pdf" target="_blank">Paper</a> / <a href="assets/pdf/bsc_thesis_talk.pdf" target="_blank">Slides</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseBraun2022BSCTHESIS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseBraun2022BSCTHESIS"><div class="card card-body"><pre><code>@InProceedings{Braun2022BSCTHESIS, 
	author = {Joschka Braun}, 
	title = {Verbal Epistemic Uncertainty Estimation for Numeric Values with GPT-3}, 
	booktitle = {BSc Thesis at Univesity of Tübingen}, 
	year = {2022}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/neurips_2025_biosecurity_workshop.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://openreview.net/forum?id=ZNZn43baQX" target="_blank">Resisting RL Elicitation of Biosecurity Capabilities: Reasoning Models Exploration Hacking on WMDP</a> <br><span style="font-weight: bold";>Joschka Braun</span>, <a href="https://scholar.google.com/citations?user=jXfklAEAAAAJ" target="_blank">Yeonwoo Jang</a>, <a href="https://scholar.google.com/citations?hl=en&user=_TQEoLgAAAAJ" target="_blank">Damon Falck</a>, Roland S. Zimmermann, David Lindner, Scott Emmons <br><span style="font-style: italic;">NeurIPS 2025 Workshop on Biosecurity Safeguards for Generative AI</span>, 2025 <br><a href="https://openreview.net/forum?id=ZNZn43baQX" target="_blank">Paper</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsebraun2025_resisting_rl" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapsebraun2025_resisting_rl"><div class="card card-body"><pre><code>@InProceedings{braun2025_resisting_rl, 
	author = {Joschka Braun and Yeonwoo Jang and Damon Falck and Roland S. Zimmermann and David Lindner and Scott Emmons}, 
	title = {Resisting RL Elicitation of Biosecurity Capabilities: Reasoning Models Exploration Hacking on WMDP}, 
	booktitle = {NeurIPS 2025 Workshop on Biosecurity Safeguards for Generative AI}, 
	year = {2025}, 
}</pre></code></div></div> </div> </div> </div>
                </div>
            </div>
            <div class="row" style="margin-top: 3em;">
                <div class="col-sm-12" style="">
                    <h4>Talks</h4>
                    <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/bsc_thesis_talk.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Verbal Epistemic Uncertainty Estimation for Numeric Values with GPT-3<br><span style="font-style: italic;">University of Tübingen</span>, 2022 <br><a href="https://JoschkaCBraun.github.io/assets/pdf/bsc_thesis_talk.pdf" target="_blank">Slides</a> </div> </div> </div>
                </div>
            </div>
            <div class="row" style="margin-top: 3em;">
                <div class="col-sm-12" style="">
                    <h4>Projects</h4>
                    <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/projects/steering_vector_blog_post.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="assets/pdf/steering_blog_post.pdf" target="_blank">A Sober Look at Steering Vectors for LLMs</a> <br><span style="font-weight: bold";>Joschka Braun</span>, <a href="https://krasheninnikov.github.io/about/" target="_blank">Dmitrii Krasheninnikov</a>, <a href="https://uzman-anwar.github.io/" target="_blank">Usman Anwar</a>, <a href="https://robertkirk.github.io/" target="_blank">Robert Kirk</a>, <a href="https://dtch1997.github.io/" target="_blank">Daniel Tan</a>, <a href="https://scholar.google.ca/citations?user=5Uz70IoAAAAJ&hl=en" target="_blank">David Krueger</a> <br><span style="font-style: italic;">Blog post on the key challenges in controlling LLM behaviour with steering vectors. Published on The Alignment Forum.</span>, 2024 <br><a href="https://www.alignmentforum.org/posts/QQP4nq7TXg89CJGBh/a-sober-look-at-steering-vectors-for-llms" target="_blank">Project Page</a> / <a href="assets/pdf/steering_blog_post.pdf" target="_blank">Paper</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseBraun_Steering_Blog_Post_2024" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseBraun_Steering_Blog_Post_2024"><div class="card card-body"><pre><code>@InProceedings{Braun_Steering_Blog_Post_2024, 
	author = {Joschka Braun and Dmitrii Krasheninnikov and Usman Anwar and Robert Kirk and Daniel Tan and David Krueger}, 
	title = {A Sober Look at Steering Vectors for LLMs}, 
	booktitle = {Blog post on the key challenges in controlling LLM behaviour with steering vectors. Published on The Alignment Forum.}, 
	year = {2024}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/projects/logits_reweighting.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="assets/pdf/logits_reweighting.pdf" target="_blank">Logit Reweighting for Topic-Focused Summarization</a> <br><span style="font-weight: bold";>Joschka Braun</span>, <a href="https://scholar.google.com/citations?user=NexA8EEAAAAJ&hl=en" target="_blank">Bálint Mucsányi</a>, <a href="https://scholar.google.ch/citations?user=UkzwC_EAAAAJ&hl=en" target="_blank">Seyed Ali Bahrainian</a> <br><span style="font-style: italic;">Implemented a custom LogitsProcessor class to reweight logits of topic-relevant tokens during summary generation. Evaluated and compared different strategies on the NEWTS dataset.</span>, 2024 <br><a href="assets/pdf/logits_reweighting.pdf" target="_blank">Paper</a> / <a href="https://github.com/JoschkaCBraun/topical-decoding" target="_blank">Code</a> / <a href="https://arxiv.org/abs/2507.05235" target="_blank">arXiv</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseBraun_Reweighting_Logits_2024" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseBraun_Reweighting_Logits_2024"><div class="card card-body"><pre><code>@InProceedings{Braun_Reweighting_Logits_2024, 
	author = {Joschka Braun and Bálint Mucsányi and Seyed Ali Bahrainian}, 
	title = {Logit Reweighting for Topic-Focused Summarization}, 
	booktitle = {Implemented a custom LogitsProcessor class to reweight logits of topic-relevant tokens during summary generation. Evaluated and compared different strategies on the NEWTS dataset.}, 
	year = {2024}, 
	eprint = {2507.05235}, 
}</pre></code></div></div> </div> </div> </div>
                </div>
            </div>
            <div class="row" style="margin-top: 3em;">
                <div class="col-sm-12" style="">
                    <h4>Public Debates</h4>
                    <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/public_debates/rwi_debate.jpeg" class="img-fluid img-thumbnail" alt="Debate image"></div><div class="col-sm-9">RWI-Wirtschaftsgespräch: AI Regulation Debate 2023<br><span style="font-style: italic;">I debated risk-based AI regulation with Ina Brandes, Minister for Culture and Science of North Rhine-Westphalia, as part of the RWI-Wirtschaftsgespräch 2023. Our discussion centered on balancing innovation and societal-scale risks to ensure artificial intelligence provides a net benefit to society.</span><br><a href="https://youtu.be/kAo-HU7UrWQ?si=eC5IIXzqIhc3PW9s&t=3584" target="_blank">Video</a> / <a href="https://www.vdch.de/rwi-wirtschaftsgespraeche-2023/" target="_blank">Link</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/public_debates/ddm_2020.png" class="img-fluid img-thumbnail" alt="Debate image"></div><div class="col-sm-9">German Debating Champion 2020<br><span style="font-style: italic;">With my teammate Dominik Hermle, I defended the 2020 German Debating Championship (DDM) title, becoming the first team in the event's 20-year history to win in consecutive years. The final round topic was "Should Western countries no longer intervene militarily abroad?"</span><br><a href="https://youtu.be/FQzVmqNpZXY?si=JsnCPQpFJw5IWvFI&t=2765" target="_blank">Video</a> / <a href="https://www.achteminute.de/20201027/die-ddm-2020-daten-und-ergebnisse/" target="_blank">Link</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/public_debates/ddm_2019.jpg" class="img-fluid img-thumbnail" alt="Debate image"></div><div class="col-sm-9">German Debating Champion 2019<br><span style="font-style: italic;">Winner of the 2019 German Debating Championship (DDM), the largest and most prestigious German-speaking debate competition. The final round topic was "Should we fight populism with the methods of populism?"</span><br><a href="https://youtu.be/3BJ2iy4loHc?si=avKLOIyzfj8_PZe0&t=2880" target="_blank">Video</a> / <a href="https://www.achteminute.de/20190603/streitkultur-tuebingen-gewinnt-die-ddm-2019/" target="_blank">Link</a> </div> </div> </div>
                </div>
            </div>
            <div class="row" style="margin-top: 3em;">
                <div class="col-sm-12" style="">
                    <h4>Miscellaneous</h4>
                    <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/misc/exploration_hacking_af_post.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://www.alignmentforum.org/posts/Dft9vpMnEeWFE3Gc6/exploration-hacking-can-reasoning-models-subvert-rl-1" target="_blank">Exploration hacking: can reasoning models subvert RL?</a> <br><span style="font-weight: bold";>Joschka Braun</span>, <a href="https://scholar.google.com/citations?hl=en&user=_TQEoLgAAAAJ" target="_blank">Damon Falck</a>, <a href="https://scholar.google.com/citations?user=jXfklAEAAAAJ" target="_blank">Yeonwoo Jang</a> <br><span style="font-style: italic;">Exploration hacking, where models subvert their RL training by selectively under-exploring, could threaten both the development of beneficial capabilities and the effectiveness of safety training.</span>, 2025 <br><a href="https://www.alignmentforum.org/posts/Dft9vpMnEeWFE3Gc6/exploration-hacking-can-reasoning-models-subvert-rl-1" target="_blank">Project Page</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseBraun_Exploration_Hacking_Blog_Post_2025" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseBraun_Exploration_Hacking_Blog_Post_2025"><div class="card card-body"><pre><code>@InProceedings{Braun_Exploration_Hacking_Blog_Post_2025, 
	author = {Joschka Braun and Damon Falck and Yeonwoo Jang}, 
	title = {Exploration hacking: can reasoning models subvert RL?}, 
	booktitle = {Exploration hacking, where models subvert their RL training by selectively under-exploring, could threaten both the development of beneficial capabilities and the effectiveness of safety training.}, 
	year = {2025}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/misc/anthropic_hackathon_2025.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="assets/pdf/anthropic_hackathon_2025.pdf" target="_blank">Anthropic Alignment Hackathon: Exploration Hacking</a> <br><span style="font-weight: bold";>Joschka Braun</span>, <a href="https://scholar.google.com/citations?hl=en&user=_TQEoLgAAAAJ" target="_blank">Damon Falck</a>, <a href="https://scholar.google.com/citations?user=jXfklAEAAAAJ" target="_blank">Yeonwoo Jang</a> <br><span style="font-style: italic;">Participated in the June 2025 <a href="https://www.anthropic.com/" target="_blank">Anthropic</a> Alignment Hackathon in San Francisco, co-developing an "Exploration Hacking" prototype over two days alongside Damon Falck and Yeonwoo Jang.</span>, 2025 <br><a href="assets/pdf/anthropic_hackathon_2025.pdf" target="_blank">Slides</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseBraun_Anthropic_Hackathon_2025" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapseBraun_Anthropic_Hackathon_2025"><div class="card card-body"><pre><code>@InProceedings{Braun_Anthropic_Hackathon_2025, 
	author = {Joschka Braun and Damon Falck and Yeonwoo Jang}, 
	title = {Anthropic Alignment Hackathon: Exploration Hacking}, 
	booktitle = {Participated in the June 2025 <a href="https://www.anthropic.com/" target="_blank">Anthropic</a> Alignment Hackathon in San Francisco, co-developing an "Exploration Hacking" prototype over two days alongside Damon Falck and Yeonwoo Jang.}, 
	year = {2025}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/misc/hcast_paper.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2503.17354" target="_blank">HCAST: Human-Calibrated Autonomy Software Tasks</a> <br>David Rein al. <br><span style="font-style: italic;">Acknowledged Contributor to HCAST benchmark: Contributed task feedback and set human performance baselines for ML Engineering tasks.</span>, 2025 <br><a href="https://arxiv.org/abs/2503.17354" target="_blank">Project Page</a> / <a href="https://arxiv.org/abs/2503.17354" target="_blank">arXiv</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapserein2025hcasthumancalibratedautonomysoftware" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button><div class="collapse" id="collapserein2025hcasthumancalibratedautonomysoftware"><div class="card card-body"><pre><code>@InProceedings{rein2025hcasthumancalibratedautonomysoftware, 
	author = {David Rein al.}, 
	title = {HCAST: Human-Calibrated Autonomy Software Tasks}, 
	booktitle = {Acknowledged Contributor to HCAST benchmark: Contributed task feedback and set human performance baselines for ML Engineering tasks.}, 
	year = {2025}, 
	eprint = {2503.17354}, 
}</pre></code></div></div> </div> </div> </div>
                </div>
            </div>
            <div class="row" style="margin-top: 3em; margin-bottom: 1em;">
                
            <div class="col-sm-12" style="">
                <h4>Homepage Template</h4>
                <p>
                    This website is based on the template of <a href="https://m-niemeyer.github.io/" target="_blank">Michael Niemeyer</a>. Check out his <a href="https://github.com/m-niemeyer/m-niemeyer.github.io" target="_blank">Github repository</a> for instructions on how to use it.
                </p>
            </div>
    
            </div>
        </div>

        <!-- Optional JavaScript -->
        <!-- jQuery first, then Popper.js, then Bootstrap JS -->
        <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
        integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
        integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
        crossorigin="anonymous"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
        integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
        crossorigin="anonymous"></script>
    </body>

    </html>
    